{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.full((800, 800, 3), 255, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness = 2\n",
    "\n",
    "cv2.rectangle(img, (100, 200), (700, 600), (255, 0, 0), thickness=thickness)\n",
    "cv2.line(img, (100, 200), (700, 600), (255, 0, 0), thickness=thickness)\n",
    "cv2.line(img, (700, 200), (100, 600), (255, 0, 0), thickness=thickness)\n",
    "\n",
    "img2 = np.zeros_like(img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [0, 255, 255], [255, 174, 0], [0,0,0]] # red, green, blue, sky, orange, black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x160943fe408>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYY0lEQVR4nO3de5BV1ZXH8e+iW4wCvsA4JDpRI6OQmVGQilpJJYaHGkzU1KhpJj6SMIUmCjoB5Z2poRE0MRpNZrSpPGyi0SiJSoxiEDVT84dGHgYU1KCJFQXloRGNMIKs+ePs25xuGvve7vs6Z/8+VV3ce+6F3qcvvc4+a52zl7k7IhKvXrUegIjUloKASOQUBEQipyAgEjkFAZHIKQiIRK4iQcDMzjCz581snZlNrcT3EJHysHJfJ2BmDcALwGjgFeApYKy7rynrNxKRsqjETOCTwDp3f8nd3wPuAs6uwPcRkTJorMC/+VHgL6nnrwAndXyTmY0HxgPQhxM5rgIjEZHdlrPZ3Q/tuLkSQaAo7j4fmA9gw81ZVquRiETCeLmzzZU4HXgVOCL1/PCwTUTqUCWCwFPAIDM7ysx6A03Aogp8HxEpg7KfDrj7TjO7HHgYaAB+4u7Plvv7iEh5VCQn4O4PAg9W4t8WkfLSFYMikVMQEImcgoBI5BQERCKnICASOQUBkcgpCIhETkFAJHIKAiKRUxAQiZyCgEjkFAREIqcgIBI5BQGRyCkIiEROQUAkcgoCIpFTEBCJXJdBwMx+YmYbzeyZ1LZDzGyJmf0x/Hlw2G5mdnNoP7bKzIZVcvAi0nPFzARuA87osG0qsNTdBwFLw3OAzwODwtd44JbyDFNEKqXLIODu/wO80WHz2UBreNwKnJPavsATTwAHmdnAMo1VRCqguzmBw9x9Q3j8GnBYeNxZC7KPdvN7iEgV9Dgx6Elb45JbG5vZeDNbZmbL2NTTUYhId3U3CLxemOaHPzeG7UW3IHP3+e4+3N2Hs0eLRBGplu4GgUXAxeHxxcD9qe0XhSrBycBbqdMGEalDXXYgMrM7gVOBAWb2CvAfwLXA3WY2DngZOD+8/UFgDLAOeBf4WgXGLCJlZMkpfY0HodbkIpVnLHf34R0364pBkcgpCIhETkFAJHIKAiKRUxAQiZyCgEjkFAREIqcgIBI5BQGRyCkIiEROQUAkcgoCIpFTEBCJnIKASOQUBEQipyAgEjkFAZHIKQiIRE5BQCRyxfQiPMLMHjOzNWb2rJldEbarH6FIDnS52jCwE5jk7ivMrB+w3MyWAF8l6Ud4rZlNJelHOIX2/QhPIulHeFIlBl8yh167aj0Ikd129QKstmPoMgiEvgEbwuO3zWwtSWuxs0mWIoekH+HjJEGgrR8h8ISZHWRmA+uh/0C/t2H+ePi7V3vxNv3wWv/0JUoG7M+70Ps9rvw+PPNPtR1PMTOBNmZ2JDAUeJLS+xG2CwJmNp6kczH8fYmj7qY+f4N/XvVh3tr3aJ7+w0nM9/Fs5YDqfHMRYB92MIYH+Xbf2Xy430Y+9nKGgoCZ9QV+CVzp7lvNdh9F3d3NrKQGBu4+H5gPoe9AlfzpqKP4tx/9iok33szcW6bT/M4sVjIUV45UKsoZyAam2HVcPLiV/S7cjj9V6zElivqfb2b7kASAO9z9V2Fzj/sR1srmAQOYOW8OP7hvAvOGTWMS36MP79CNvqoiXWpkB2exiEf6jOKSphb2m74d/oGa5wIKiqkOGPBjYK2735B6KdP9CHc1NPDoiBF8ZfEdHHzVm/ys34WcyHIMZQ6lXJyP8Co/sAncOWQsQ2auxf4F2J+6CQBQ3OnAp4ALgdVm9nTYNp089CM0Y/OhhzJrXjOfO+0x5kyZySMrR9Hil/AOfamrT0oypYGdnMlvmNd3GoO/uBYbA/Sp9ag6V0x14H/Z+2/DyE7e78BlPRxXVe1qaGDpyJE8/fAJTP7O9dz+3xcw+2/fZgXDUCCQ0jgfYT0zmZOc+1+8DRtEXf83Kqk6kGtmbBkwgJlz5/DZ03/HNVNm8MiKUcz38bytCoIUoTFk/tsd/ets6t8ZpcQ7eL+xkUdHjODCh35G/8lbWND3IoYpVyAfyBnIem62idw1uIkhM8K5fx/qPgCAgkDnQq5AFQTpSiM7OJv7eaTPKC5tupX9ZoTMf4Z+szI01OpLVxAOueoNVRAkZXfm/+dD/pUhs+oz818MBYGupGYFP7z3cuacOJNJ9j368jaaFcSpgZ2cxSKW9B3NJU0t7D9tW+aO/mkZHXb1FWYFFyy+nf6Tt3B7nwsYykoUCGISjv5M4M7BYxk8Yy12LnVb+iuWqgOl6KSC8OiKEbT4Jaog5FwjOziT3zC37/RMZf6LoZlANxQqCBc9tEAVhNzbnfm/c/DYzGX+i6Eg0F0hVzBj3jXtKgjKFeRH+pr/rGb+i5Gz3am+jvcgLOh3kSoImZeNa/7LRUGgHFL3IPzw3suZM2wm37IbNCvIoE4z/8eS69+UHO9a9bVVEB6+nQGTN3N73wsYxgoUCLIgOfr/kMuTzP/MfGT+i6HqQLl1UkFYumKkKgh1LKvX/JeLZgIVkr4H4ZDJb6iCUJeSzP8PbAJ3DcneNf/loiBQSR3vQRiqexDqRSHzv6TPaC75cmq1nwh/IyLc5eprqyA8rHsQai8597/ZJnLnkLF8Yuaa5Nw/oul/R8oJVEtqVnDq6Y8z5+qZrFw5lO/5JLbQn2j/B1ZR22o/faYx+Kz6Xu2nmjQTqLJ0BaHX5F0s7HsuI3iUBnbWemg51uGa/1nxZP6LUcxCox8ys9+b2R9CG7L/DNuPMrMnQ7uxX5hZ77B93/B8XXj9yArvQ/aECsKMudfQfN8sZp44hzk2k/5sRrmC8mo79+87mkvH3sr+0+t/ua9qK2Ym8H/ACHc/HjgBOCOsInwdcKO7HwO8CYwL7x8HvBm23xjeJ50oVBDOf+hubLK3zQp68X6th5YDqcx/Blf7qaYug4An3glP9wlfDowAFobtrcA54fHZ4Tnh9ZGW7lQi7YVcwfR5c2m+bxazhjUzl+kMYBOaFXRPerWfS5pacnvNf7kU23ykISw3vhFYArwI/NXdCyeyhVZjkGpDFl5/C+jfyb853syWmdkyNvVoH3KhkCs4b/E9cBXc0+88zQpKlp/VfqqpqCDg7u+7+wkk3YQ+CRzX02/s7vPdfbi7D+fQnv5rOZGeFdw7i1knNjPXpitXUIS8rfZTTSX9iNz9r8BjwCnAQWZWKDGmW421tSELrx8IbCnHYGNRmBWcu3ghTEYVhA+Uz9V+qqmY6sChZnZQeLwfMBpYSxIMzg1v69iGrNCe7Fzg0dCQREqRqiDMuXcms05sVgWhg04z/3XU4y8ripkJDAQeM7NVwFPAEnd/AJgCfMvM1pGc8/84vP/HQP+w/VvA1PIPOx7vNzaydORIznvoHlUQ2ijzX07FtCFbBQztZPtLJPmBjtu3A+eVZXSSSOUKTj39cWZd3cxpK37L9UxmMwOI6X9+2x1/hav+zgT2I6YfQdkpbZIhHSsId/c7P6JZQVyr/VST7h3Ims5mBSt/y3f9qtzeg5ClDr9ZpJlARrVVEB5eiE+2nFYQwmo/Ft9qP9WkmUCWdVjFaOaUOZy2Ih+zgthX+6kmzQRyIH0PApPIeAUh2x1+s0gzgbwo5AquncupZ2SzgqDMf21oJpAz2awgpLr8KPNfdZoJ5FEnFYTRK5dwvU+uu1yBVvupPc0EcixdQUhfbVgfFYRU3X/w2OSOP2X+a0IzgbxL3YPw2dN/x6wpzTWvICjzX180E4hEoYJw3kP3tLuuoLq5Aq3zX480E4hJqpPyqac/zsyr51StgtBp5n//in07KYFmAhEq5ArOX3w3frVVeBWjDtf8p1f7kbqgmUCsCrOCuddw6mmVqSA0sJMxPMi1faYq81/HNBOIXLsKwqRyVRB2H/3vGtyU1P2V+a9bmgnI7gpCyBXMmtL9OxOV+c8ezQSkTdsqRovvabe2YXG5AmX+s0ozAWmvG6sYKfOfbUXPBELvgZVm9kB4rjZkOVZcH4TdR/89rvmXzCjldOAKklWGC9SGLO869kEYlvRBGMCmtnX+C11+9p+2DY5FJ5gZVGwHosOBM4EfheeG2pBFI11BYBIs7HMudzKWO48bq8x/DhQbt78PXA3sCs/7ozZkcTHjrQMP5Pcnf5JDDlzHibaQDx21LVmQXjKtmOYjXwA2uvvycn5jtSHLEHcGrl/P9ydOZPwFFzB+/XpOdrj+IXh7Nvhqdh8eJHOKmQl8CjjLzP4M3EVyGnATakMWhcYdOzhr0SLuGTWKDS0tnL99O08Am4BpwDkvwYrrwG8HtqLmSBlUTGvyae5+uLsfCTSRtBX7CmpDlm+po/83x45l0tq1zHNna+otu4BHgTO2wXfvg62zAc0KMqcnuVy1Icuphp07dx/9b72VL2/bxpPs/Xd7M8ms4EsvwfJrYZdmBZlS0sVC7v448Hh4rDZkeePOR9avZ0ZzMx9fsIBJ27bxe4r7XS7MCk7fDlffD99YDX0vBPsE0FDRUUsPqaorwO5z/1+MHs2rLS1tR/9SD+ZbgOkO57yoWUFW6LLh2LkzcMMGZs6ezcdbW5m8fXvRR/+9eZ+QK0jPCi4C+0d02KlD+kgi1pb5Hz2a9fPnc/727d06+u/NFlRByALNBGIUjv4zmps5prWVyeHcvxJJ/XQF4ar74NJVcMBFgGYFdUMfQ2Qadu7ki7/+dbvM/xNUvqqnCkL90kwgFj3I/JdLuoIw5X64VBWEuqCZQATSmf/1Pcj8l8sWYJrDlwoVhDvQrKCGNBPIs8K5/+zZybl/GTL/5fI+sJRQQbgPvrFKFYRa0Y87p9LX/Fci818uqiDUnmYCeRPO/ac3N3NMOPd/ivq+nL+zCkI/zQqqRj/iHGncsYOz7r+fu0eNanfuX88BIC1dQVhxLez6GZoVVIFmAnlQyPzPmcPHW1trkvkvl3b3ICyCbzyjCkKlaSaQce0y/6k7/rIYANIK9yCoglB5mglkVfqqv9tuq6vMf7moglAd+lFmUPqa/8JqP3k4+u+NKgiVpZlAlnS45j8Lmf9yUQWhcvTjy4i2o//IkUWt9pNXqiCUn2YC9S51zf/RNbrmv97sUUEorFegCkK3FNt85M9mttrMnjazZWHbIWa2xMz+GP48OGw3M7s5tCFbZWbDKrkDeVY4+t89ahSvtrTQlJPMf7m0rWKkOxN7pJTTgc+5+wnuPjw8nwosdfdBJEncwoKinwcGha/xwC3lGmw0Uiv9XtbUxOTnnmMeSRcXaS+9itH1i9QHoTt6khNItxvr2IZsgSeeIOlPoD41ReqY+T8vrPOvg9sHK9yZqApC6YoNAg781syWm9n4sO0wd98QHr8GHBYet7UhC9ItytqoDVkHhaP/hAl8s6mJyWvW7LHOv3ywzvog+DNoVtCFYoPAp919GMlU/zIz+0z6xdBcpKSYqzZku7W746+lhS+Ho7/+73ZPuwrCPOUKulJUdcDdXw1/bjSze0n6DbxuZgPdfUOY7m8Mb29rQxakW5RJWuqa/6Mzfs1/vdmjD8IqVRD2ppiGpH3MrF/hMXAa8Azt2411bEN2UagSnAy8lTptkKDQ5efucM2/Mv+VsUcFQfcg7KGYmcBhwL1mVnj/z919sZk9BdxtZuOAl4Hzw/sfBMYA64B3ga+VfdRZFq76mz57NoNaW5mUw2v+680efRB0D0I7XQaB0G7s+E62bwFGdrLdgcvKMrqcadyxgzEPPsjl06ax8LnnmObOO7UeVEQKFYSHX4LvXAdDT4deZwMHAFbjwdWQrhishtTRf0BrKxO3b+e5Wo8pUroHYU+R7nb1FDL/C0aNYnVLC19TAKgLe9yDEHEFQTOBSgmZ/ylz5nDoggVMfPddniPK/2N1S52UE5oJVEDDzp18cdEiFowezZpbb+Xr777LWhQA6lW6k/KKCCsImgmUUzj3n9bczKG33caE7dtZW+sxSVEKFYQ9riuIIFeQ892rnsK5f+vo0Tzb0sLXFQAyqeM9CDHkCjQT6KkOmf8r9MufebFVEHK4S9XTlvkfObIt868AkB+FCkLb1YY5XcVIM4HuCJn/qc3N9F+wgInbtinzn1O7gMcIVxsuSjop98vZPQiaCZSocM3/glGjeKalhXHbtinzH4G2Pgg5XMVIM4FiKfMfvXb3IKTXNsx4riDDQ6+etsz/qFE829LCOAWAqBUqCF/KSQVBM4EPomv+ZS92EbojbUu6I12S4QpCxoZbPbrmX4qxmWSF3Szfg6CZQEfpa/5bW5X5ly51vAfh0tXQL0P3IGgmkNKW+S9c86/Mv5Qgq52UNROAtqP/tOZmBrS2crmm/tJNWVzFqE6HVT2Fc//bTjuNZ+bPZ5wCgJRBlioIxbYhO8jMFprZc2a21sxOyXwbsrDO/40TJzK2qYkr1qyhxZ13az0uyY10BeH6+0IfhDrsjlTsTOAmYLG7H0ey3uBaMtyGrDF11d/qW2/VNf9SUXtdxahOdJkTMLMDgc8AXwVw9/eA98zsbODU8LZW4HFgCqk2ZMATYRYxsF6WHT/kjTe5YeJE+v/85/x7WO1nFzovksr7HTAmVUHYv0+tR5QoJjF4FLAJ+KmZHQ8sB66g9DZkNQ8CO/aBA7a+wJcWvsDq3nBN71qPSGLUCLy+Bfq9BVsPqPVoigsCjcAwYIK7P2lmN7F76g8ky4ybWUkpj9DTMOlr+Pel/M3u29IfPvcY9H6vOt9P5IPs6gUbP1zrURQXBF4BXnH3J8PzhSRBoEdtyNx9PjAfwIaXFkC6zWBTHfzQRepJl6fC7v4a8BczOzZsGgmsQW3IRHKh2IuFJgB3mFlv4CWS1mK9UBsykcyzJIlf40EMN2dZrUchknPGcncf3nGzKmMikVMQEImcgoBI5BQERCKnICASOQUBkcgpCIhETkFAJHIKAiKRUxAQiZyCgEjkFAREIqcgIBI5BQGRyCkIiEROQUAkcgoCIpFTEBCJXJdBwMyONbOnU19bzezKzLchExGguNWGn3f3E9z9BOBEksVD7yXDbchEZLdSTwdGAi+6+8sk7cZaw/ZW4JzwuK0Nmbs/ARwU+hKISB0qNQg0AXeGx6W2IROROlR0EAg9B84C7un4Wmg+WnIbMjNbZmbL2FTK3xSRciplJvB5YIW7vx6ev16Y5ne3DZm7D3f34Rxa+sBFpDxKCQJj2X0qAGpDJpILRbUhM7M+wGjgktTma1EbMpHMUxsykVioDZmIdEZBQCRyCgIikVMQEImcgoBI5BQERCKnICASOQUBkcgpCIhETkFAJHIKAiKRUxAQiZyCgEjkFAREIqcgIBI5BQGRyCkIiEROQUAkcgoCIpFTEBCJnIKASOQUBEQiVx9Ljpu9DTxf63FUyABgc60HUQHar+z5mLvv0e+rqOYjVfB8Z+uh54GZLcvjvmm/8kOnAyKRUxAQiVy9BIH5tR5ABeV137RfOVEXiUERqZ16mQmISI0oCIhEruZBwMzOMLPnzWydmU2t9XhKYWZHmNljZrbGzJ41syvC9kPMbImZ/TH8eXDYbmZ2c9jXVWY2rLZ78MHMrMHMVprZA+H5UWb2ZBj/L8ysd9i+b3i+Lrx+ZE0H3gUzO8jMFprZc2a21sxOyctn1h01DQJm1gD8F/B5YAgw1syG1HJMJdoJTHL3IcDJwGVh/FOBpe4+CFgankOyn4PC13jgluoPuSRXAGtTz68DbnT3Y4A3gXFh+zjgzbD9xvC+enYTsNjdjwOOJ9nHvHxmpXP3mn0BpwAPp55PA6bVckw93J/7gdEkVz8ODNsGklwMBdACjE29v+199fYFHE7yyzACeAAwkivpGjt+dsDDwCnhcWN4n9V6H/ayXwcCf+o4vjx8Zt39qvXpwEeBv6SevxK2ZU6YAg8FngQOc/cN4aXXgMPC4yzt7/eBq4Fd4Xl/4K/uvjM8T4+9bb/C62+F99ejo4BNwE/Dqc6PzKwP+fjMuqXWQSAXzKwv8EvgSnffmn7Nk8NHpuqwZvYFYKO7L6/1WCqgERgG3OLuQ4G/sXvqD2TzM+uJWgeBV4EjUs8PD9syw8z2IQkAd7j7r8Lm181sYHh9ILAxbM/K/n4KOMvM/gzcRXJKcBNwkJkV7jdJj71tv8LrBwJbqjngErwCvOLuT4bnC0mCQtY/s26rdRB4ChgUss69gSZgUY3HVDQzM+DHwFp3vyH10iLg4vD4YpJcQWH7RSHjfDLwVmoKWjfcfZq7H+7uR5J8Jo+6+1eAx4Bzw9s67ldhf88N76/LI6m7vwb8xcyODZtGAmvI+GfWI7VOSgBjgBeAF4EZtR5PiWP/NMm0cRXwdPgaQ3I+vBT4I/AIcEh4v5FUQ14EVgPDa70PRezjqcAD4fHRwO+BdcA9wL5h+4fC83Xh9aNrPe4u9ukEYFn43O4DDs7TZ1bqly4bFolcrU8HRKTGFAREIqcgIBI5BQGRyCkIiEROQUAkcgoCIpH7f0PxECeUQT6LAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(cnt):\n",
    "    # img2[labels==i] = [int(j) for j in np.random.randint(0, 255, 3)]\n",
    "    img2[labels==i] = colors[i]\n",
    "\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = img2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[150][140] = [0,0,0]#[[0,0,0] for _ in range(800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1609811d088>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['x','y','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "    x = np.random.randint(0, 800)\n",
    "    y = np.random.randint(0, 800)\n",
    "    label = labels[y][x]\n",
    "    temp = pd.DataFrame({'x':[x], 'y':[y], 'label':[label]})\n",
    "\n",
    "    data = data.append(temp, ignore_index=True)\n",
    "\n",
    "X_data = data.drop(columns=['label']).values\n",
    "y_data = data['label'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.int32)\n",
    "# X_test = tf.convert_to_tensor(X_test, dtype=tf.int32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)\n",
    "# y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "      <td>575</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>393</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>740</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>273</td>\n",
       "      <td>404</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>246</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>123</td>\n",
       "      <td>297</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>570</td>\n",
       "      <td>789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>729</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x    y label\n",
       "0     420  575     5\n",
       "1      79  580     1\n",
       "2      55   49     1\n",
       "3     393  602     1\n",
       "4     740  444     1\n",
       "...   ...  ...   ...\n",
       "9995  273  404     3\n",
       "9996  246  242     2\n",
       "9997  123  297     3\n",
       "9998  570  789     1\n",
       "9999  729  760     1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 17,158\n",
      "Trainable params: 17,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=(2,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/yhkim/Innopia4/runs/2rw09tz9\" target=\"_blank\">colorful-firefly-15</a></strong> to <a href=\"https://wandb.ai/yhkim/Innopia4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9730 - val_loss: 0.1107 - val_accuracy: 0.9740\n",
      "Epoch 2/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9775 - val_loss: 0.1070 - val_accuracy: 0.9755\n",
      "Epoch 3/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9769 - val_loss: 0.1106 - val_accuracy: 0.9710\n",
      "Epoch 4/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9778 - val_loss: 0.1103 - val_accuracy: 0.9725\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9776 - val_loss: 0.1084 - val_accuracy: 0.9730\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9779 - val_loss: 0.1091 - val_accuracy: 0.9670\n",
      "Epoch 7/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9779 - val_loss: 0.1040 - val_accuracy: 0.9755\n",
      "Epoch 8/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9770 - val_loss: 0.1077 - val_accuracy: 0.9710\n",
      "Epoch 9/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.9758 - val_loss: 0.1066 - val_accuracy: 0.9730\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9736 - val_loss: 0.1255 - val_accuracy: 0.9560\n",
      "Epoch 11/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9756 - val_loss: 0.1040 - val_accuracy: 0.9770\n",
      "Epoch 12/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9786 - val_loss: 0.1082 - val_accuracy: 0.9675\n",
      "Epoch 13/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9783 - val_loss: 0.1085 - val_accuracy: 0.9710\n",
      "Epoch 14/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9756 - val_loss: 0.1071 - val_accuracy: 0.9680\n",
      "Epoch 15/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9760 - val_loss: 0.1048 - val_accuracy: 0.9695\n",
      "Epoch 16/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9775 - val_loss: 0.1035 - val_accuracy: 0.9730\n",
      "Epoch 17/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9776 - val_loss: 0.1064 - val_accuracy: 0.9690\n",
      "Epoch 18/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9761 - val_loss: 0.0998 - val_accuracy: 0.9745\n",
      "Epoch 19/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9769 - val_loss: 0.0988 - val_accuracy: 0.9740\n",
      "Epoch 20/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9803 - val_loss: 0.0982 - val_accuracy: 0.9740\n",
      "Epoch 21/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9797 - val_loss: 0.1033 - val_accuracy: 0.9645\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9719 - val_loss: 0.1010 - val_accuracy: 0.9720\n",
      "Epoch 23/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9759 - val_loss: 0.1007 - val_accuracy: 0.9725\n",
      "Epoch 24/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9766 - val_loss: 0.1014 - val_accuracy: 0.9725\n",
      "Epoch 25/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9762 - val_loss: 0.1062 - val_accuracy: 0.9675\n",
      "Epoch 26/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9759 - val_loss: 0.1026 - val_accuracy: 0.9710\n",
      "Epoch 27/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9801 - val_loss: 0.0921 - val_accuracy: 0.9780\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9809 - val_loss: 0.0971 - val_accuracy: 0.9775\n",
      "Epoch 29/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9800 - val_loss: 0.0971 - val_accuracy: 0.9705\n",
      "Epoch 30/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9800 - val_loss: 0.0936 - val_accuracy: 0.9760\n",
      "Epoch 31/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9753 - val_loss: 0.1014 - val_accuracy: 0.9685\n",
      "Epoch 32/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9753 - val_loss: 0.1058 - val_accuracy: 0.9690\n",
      "Epoch 33/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9785 - val_loss: 0.0920 - val_accuracy: 0.9735\n",
      "Epoch 34/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9806 - val_loss: 0.0975 - val_accuracy: 0.9715\n",
      "Epoch 35/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9796 - val_loss: 0.0958 - val_accuracy: 0.9730\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9789 - val_loss: 0.0999 - val_accuracy: 0.9700\n",
      "Epoch 37/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9781 - val_loss: 0.0929 - val_accuracy: 0.9740\n",
      "Epoch 38/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9804 - val_loss: 0.0895 - val_accuracy: 0.9780\n",
      "Epoch 39/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9812 - val_loss: 0.0900 - val_accuracy: 0.9765\n",
      "Epoch 40/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9735\n",
      "Epoch 41/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9754 - val_loss: 0.1027 - val_accuracy: 0.9660\n",
      "Epoch 42/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9804 - val_loss: 0.0891 - val_accuracy: 0.9775\n",
      "Epoch 43/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9781 - val_loss: 0.0934 - val_accuracy: 0.9690\n",
      "Epoch 44/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 0.0938 - val_accuracy: 0.9730\n",
      "Epoch 45/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9810 - val_loss: 0.0906 - val_accuracy: 0.9745\n",
      "Epoch 46/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9806 - val_loss: 0.0890 - val_accuracy: 0.9755\n",
      "Epoch 47/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9803 - val_loss: 0.0870 - val_accuracy: 0.9800\n",
      "Epoch 48/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9801 - val_loss: 0.0878 - val_accuracy: 0.9780\n",
      "Epoch 49/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9758 - val_loss: 0.1007 - val_accuracy: 0.9715\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9765 - val_loss: 0.0923 - val_accuracy: 0.9740\n",
      "Epoch 51/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9799 - val_loss: 0.0918 - val_accuracy: 0.9725\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9795 - val_loss: 0.0898 - val_accuracy: 0.9755\n",
      "Epoch 53/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9811 - val_loss: 0.0915 - val_accuracy: 0.9740\n",
      "Epoch 54/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9781 - val_loss: 0.0901 - val_accuracy: 0.9750\n",
      "Epoch 55/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9809 - val_loss: 0.0956 - val_accuracy: 0.9695\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9779 - val_loss: 0.0895 - val_accuracy: 0.9770\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9786 - val_loss: 0.0891 - val_accuracy: 0.9740\n",
      "Epoch 58/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9795 - val_loss: 0.1068 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9805 - val_loss: 0.0885 - val_accuracy: 0.9740\n",
      "Epoch 60/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9786 - val_loss: 0.0873 - val_accuracy: 0.9765\n",
      "Epoch 61/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9762 - val_loss: 0.0969 - val_accuracy: 0.9700\n",
      "Epoch 62/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9779 - val_loss: 0.0900 - val_accuracy: 0.9760\n",
      "Epoch 63/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9804 - val_loss: 0.0863 - val_accuracy: 0.9790\n",
      "Epoch 64/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9804 - val_loss: 0.0957 - val_accuracy: 0.9720\n",
      "Epoch 65/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.0897 - val_accuracy: 0.9725\n",
      "Epoch 66/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9770 - val_loss: 0.0856 - val_accuracy: 0.9780\n",
      "Epoch 67/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.0854 - val_accuracy: 0.9770\n",
      "Epoch 68/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9805 - val_loss: 0.1017 - val_accuracy: 0.9655\n",
      "Epoch 69/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9781 - val_loss: 0.0875 - val_accuracy: 0.9760\n",
      "Epoch 70/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9805 - val_loss: 0.0856 - val_accuracy: 0.9780\n",
      "Epoch 71/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9829 - val_loss: 0.0927 - val_accuracy: 0.9675\n",
      "Epoch 72/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 0.0877 - val_accuracy: 0.9730\n",
      "Epoch 73/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0869 - val_accuracy: 0.9760\n",
      "Epoch 74/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9819 - val_loss: 0.0872 - val_accuracy: 0.9755\n",
      "Epoch 75/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9811 - val_loss: 0.0954 - val_accuracy: 0.9710\n",
      "Epoch 76/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9789 - val_loss: 0.0868 - val_accuracy: 0.9765\n",
      "Epoch 77/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9806 - val_loss: 0.0861 - val_accuracy: 0.9785\n",
      "Epoch 78/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9787 - val_loss: 0.0871 - val_accuracy: 0.9720\n",
      "Epoch 79/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9762 - val_loss: 0.0904 - val_accuracy: 0.9740\n",
      "Epoch 80/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9705 - val_loss: 0.0927 - val_accuracy: 0.9740\n",
      "Epoch 81/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9815 - val_loss: 0.0923 - val_accuracy: 0.9725\n",
      "Epoch 82/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9814 - val_loss: 0.0871 - val_accuracy: 0.9730\n",
      "Epoch 83/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9812 - val_loss: 0.0884 - val_accuracy: 0.9735\n",
      "Epoch 84/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 0.0896 - val_accuracy: 0.9760\n",
      "Epoch 85/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 0.0857 - val_accuracy: 0.9775\n",
      "Epoch 86/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9812 - val_loss: 0.0855 - val_accuracy: 0.9770\n",
      "Epoch 87/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9829 - val_loss: 0.0831 - val_accuracy: 0.9775\n",
      "Epoch 88/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9775 - val_loss: 0.0830 - val_accuracy: 0.9750\n",
      "Epoch 89/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9816 - val_loss: 0.0826 - val_accuracy: 0.9750\n",
      "Epoch 90/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9764 - val_loss: 0.0835 - val_accuracy: 0.9775\n",
      "Epoch 91/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9815 - val_loss: 0.0913 - val_accuracy: 0.9710\n",
      "Epoch 92/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9801 - val_loss: 0.0878 - val_accuracy: 0.9735\n",
      "Epoch 93/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.0971 - val_accuracy: 0.9725\n",
      "Epoch 94/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9800 - val_loss: 0.0970 - val_accuracy: 0.9760\n",
      "Epoch 95/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9769 - val_loss: 0.0930 - val_accuracy: 0.9675\n",
      "Epoch 96/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9793 - val_loss: 0.0890 - val_accuracy: 0.9760\n",
      "Epoch 97/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9799 - val_loss: 0.0817 - val_accuracy: 0.9765\n",
      "Epoch 98/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.0801 - val_accuracy: 0.9770\n",
      "Epoch 99/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.0813 - val_accuracy: 0.9765\n",
      "Epoch 100/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 0.0789 - val_accuracy: 0.9755\n",
      "Epoch 101/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9808 - val_loss: 0.0804 - val_accuracy: 0.9760\n",
      "Epoch 102/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.0809 - val_accuracy: 0.9760\n",
      "Epoch 103/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.0838 - val_accuracy: 0.9725\n",
      "Epoch 104/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9819 - val_loss: 0.0805 - val_accuracy: 0.9730\n",
      "Epoch 105/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.0781 - val_accuracy: 0.9780\n",
      "Epoch 106/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9820 - val_loss: 0.0937 - val_accuracy: 0.9690\n",
      "Epoch 107/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0849 - val_accuracy: 0.9730\n",
      "Epoch 108/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9790 - val_loss: 0.0808 - val_accuracy: 0.9745\n",
      "Epoch 109/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9804 - val_loss: 0.0803 - val_accuracy: 0.9770\n",
      "Epoch 110/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9814 - val_loss: 0.0802 - val_accuracy: 0.9780\n",
      "Epoch 111/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.0875 - val_accuracy: 0.9660\n",
      "Epoch 112/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9806 - val_loss: 0.0795 - val_accuracy: 0.9745\n",
      "Epoch 113/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9814 - val_loss: 0.0894 - val_accuracy: 0.9665\n",
      "Epoch 114/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9801 - val_loss: 0.0783 - val_accuracy: 0.9745\n",
      "Epoch 115/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9793 - val_loss: 0.0805 - val_accuracy: 0.9765\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9822 - val_loss: 0.0813 - val_accuracy: 0.9775\n",
      "Epoch 117/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9766 - val_loss: 0.0844 - val_accuracy: 0.9730\n",
      "Epoch 118/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.0808 - val_accuracy: 0.9760\n",
      "Epoch 119/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 0.0848 - val_accuracy: 0.9740\n",
      "Epoch 120/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9827 - val_loss: 0.0788 - val_accuracy: 0.9775\n",
      "Epoch 121/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9833 - val_loss: 0.0781 - val_accuracy: 0.9785\n",
      "Epoch 122/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9834 - val_loss: 0.0763 - val_accuracy: 0.9770\n",
      "Epoch 123/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.0792 - val_accuracy: 0.9750\n",
      "Epoch 124/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.0897 - val_accuracy: 0.9695\n",
      "Epoch 125/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.0857 - val_accuracy: 0.9700\n",
      "Epoch 126/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9794 - val_loss: 0.0990 - val_accuracy: 0.9610\n",
      "Epoch 127/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.0816 - val_accuracy: 0.9745\n",
      "Epoch 128/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9825 - val_loss: 0.0806 - val_accuracy: 0.9735\n",
      "Epoch 129/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9812 - val_loss: 0.0903 - val_accuracy: 0.9700\n",
      "Epoch 130/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9834 - val_loss: 0.0780 - val_accuracy: 0.9770\n",
      "Epoch 131/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.0814 - val_accuracy: 0.9710\n",
      "Epoch 132/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9827 - val_loss: 0.0781 - val_accuracy: 0.9730\n",
      "Epoch 133/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 0.0877 - val_accuracy: 0.9660\n",
      "Epoch 134/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9778 - val_loss: 0.0784 - val_accuracy: 0.9750\n",
      "Epoch 135/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9830 - val_loss: 0.0848 - val_accuracy: 0.9730\n",
      "Epoch 136/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9822 - val_loss: 0.0792 - val_accuracy: 0.9740\n",
      "Epoch 137/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0846 - val_accuracy: 0.9720\n",
      "Epoch 138/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9821 - val_loss: 0.0824 - val_accuracy: 0.9720\n",
      "Epoch 139/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9804 - val_loss: 0.0922 - val_accuracy: 0.9695\n",
      "Epoch 140/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9796 - val_loss: 0.1007 - val_accuracy: 0.9730\n",
      "Epoch 141/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9809 - val_loss: 0.0814 - val_accuracy: 0.9735\n",
      "Epoch 142/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9824 - val_loss: 0.0762 - val_accuracy: 0.9780\n",
      "Epoch 143/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.0906 - val_accuracy: 0.9665\n",
      "Epoch 144/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9737 - val_loss: 0.0775 - val_accuracy: 0.9750\n",
      "Epoch 145/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
      "Epoch 146/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9834 - val_loss: 0.0863 - val_accuracy: 0.9700\n",
      "Epoch 147/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9795 - val_loss: 0.0792 - val_accuracy: 0.9775\n",
      "Epoch 148/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 0.0776 - val_accuracy: 0.9725\n",
      "Epoch 149/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9837 - val_loss: 0.0747 - val_accuracy: 0.9775\n",
      "Epoch 150/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9818 - val_loss: 0.0769 - val_accuracy: 0.9775\n",
      "Epoch 151/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.0784 - val_accuracy: 0.9760\n",
      "Epoch 152/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9835 - val_loss: 0.0793 - val_accuracy: 0.9760\n",
      "Epoch 153/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9795 - val_loss: 0.0839 - val_accuracy: 0.9710\n",
      "Epoch 154/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9824 - val_loss: 0.0854 - val_accuracy: 0.9755\n",
      "Epoch 155/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.0911 - val_accuracy: 0.9655\n",
      "Epoch 156/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.0761 - val_accuracy: 0.9750\n",
      "Epoch 157/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9760 - val_loss: 0.0783 - val_accuracy: 0.9770\n",
      "Epoch 158/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9761 - val_loss: 0.0851 - val_accuracy: 0.9740\n",
      "Epoch 159/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9806 - val_loss: 0.0825 - val_accuracy: 0.9730\n",
      "Epoch 160/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9803 - val_loss: 0.0904 - val_accuracy: 0.9680\n",
      "Epoch 161/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.0804 - val_accuracy: 0.9755\n",
      "Epoch 162/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9775 - val_loss: 0.0812 - val_accuracy: 0.9765\n",
      "Epoch 163/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9775 - val_loss: 0.0948 - val_accuracy: 0.9675\n",
      "Epoch 164/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9804 - val_loss: 0.0832 - val_accuracy: 0.9710\n",
      "Epoch 165/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 0.0783 - val_accuracy: 0.9730\n",
      "Epoch 166/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9851 - val_loss: 0.0751 - val_accuracy: 0.9775\n",
      "Epoch 167/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9826 - val_loss: 0.0845 - val_accuracy: 0.9720\n",
      "Epoch 168/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9825 - val_loss: 0.0734 - val_accuracy: 0.9795\n",
      "Epoch 169/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.0861 - val_accuracy: 0.9670\n",
      "Epoch 170/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9768 - val_loss: 0.0820 - val_accuracy: 0.9730\n",
      "Epoch 171/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9780 - val_loss: 0.0848 - val_accuracy: 0.9695\n",
      "Epoch 172/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 0.0794 - val_accuracy: 0.9745\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.0783 - val_accuracy: 0.9755\n",
      "Epoch 174/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 0.0757 - val_accuracy: 0.9750\n",
      "Epoch 175/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9806 - val_loss: 0.0819 - val_accuracy: 0.9710\n",
      "Epoch 176/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9819 - val_loss: 0.0733 - val_accuracy: 0.9780\n",
      "Epoch 177/300\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.0734 - val_accuracy: 0.9770\n",
      "Epoch 178/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9833 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
      "Epoch 179/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9794 - val_loss: 0.0876 - val_accuracy: 0.9725\n",
      "Epoch 180/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9783 - val_loss: 0.0979 - val_accuracy: 0.9655\n",
      "Epoch 181/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0768 - val_accuracy: 0.9740\n",
      "Epoch 182/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 0.1116 - val_accuracy: 0.9705\n",
      "Epoch 183/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9822 - val_loss: 0.0776 - val_accuracy: 0.9720\n",
      "Epoch 184/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.0775 - val_accuracy: 0.9750\n",
      "Epoch 185/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.0777 - val_accuracy: 0.9760\n",
      "Epoch 186/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9835 - val_loss: 0.0766 - val_accuracy: 0.9755\n",
      "Epoch 187/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.0779 - val_accuracy: 0.9755\n",
      "Epoch 188/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.0779 - val_accuracy: 0.9775\n",
      "Epoch 189/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.0750 - val_accuracy: 0.9785\n",
      "Epoch 190/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.0777 - val_accuracy: 0.9740\n",
      "Epoch 191/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9831 - val_loss: 0.0793 - val_accuracy: 0.9755\n",
      "Epoch 192/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9789 - val_loss: 0.0822 - val_accuracy: 0.9730\n",
      "Epoch 193/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9826 - val_loss: 0.0914 - val_accuracy: 0.9695\n",
      "Epoch 194/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9821 - val_loss: 0.0757 - val_accuracy: 0.9755\n",
      "Epoch 195/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 0.0792 - val_accuracy: 0.9735\n",
      "Epoch 196/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.0792 - val_accuracy: 0.9740\n",
      "Epoch 197/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9806 - val_loss: 0.0771 - val_accuracy: 0.9735\n",
      "Epoch 198/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 0.0779 - val_accuracy: 0.9730\n",
      "Epoch 199/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9809 - val_loss: 0.0783 - val_accuracy: 0.9720\n",
      "Epoch 200/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9816 - val_loss: 0.1016 - val_accuracy: 0.9665\n",
      "Epoch 201/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9770 - val_loss: 0.0787 - val_accuracy: 0.9735\n",
      "Epoch 202/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0846 - val_accuracy: 0.9715\n",
      "Epoch 203/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9725 - val_loss: 0.1231 - val_accuracy: 0.9530\n",
      "Epoch 204/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9786 - val_loss: 0.0802 - val_accuracy: 0.9750\n",
      "Epoch 205/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0747 - val_accuracy: 0.9750\n",
      "Epoch 206/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.0753 - val_accuracy: 0.9745\n",
      "Epoch 207/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.0914 - val_accuracy: 0.9730\n",
      "Epoch 208/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9831 - val_loss: 0.0803 - val_accuracy: 0.9775\n",
      "Epoch 209/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9820 - val_loss: 0.0746 - val_accuracy: 0.9785\n",
      "Epoch 210/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9840 - val_loss: 0.0753 - val_accuracy: 0.9775\n",
      "Epoch 211/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9843 - val_loss: 0.0901 - val_accuracy: 0.9705\n",
      "Epoch 212/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9801 - val_loss: 0.0745 - val_accuracy: 0.9785\n",
      "Epoch 213/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9771 - val_loss: 0.0728 - val_accuracy: 0.9800\n",
      "Epoch 214/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0972 - val_accuracy: 0.9645\n",
      "Epoch 215/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9797 - val_loss: 0.0792 - val_accuracy: 0.9735\n",
      "Epoch 216/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9818 - val_loss: 0.0908 - val_accuracy: 0.9685\n",
      "Epoch 217/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9804 - val_loss: 0.0735 - val_accuracy: 0.9780\n",
      "Epoch 218/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9846 - val_loss: 0.0755 - val_accuracy: 0.9765\n",
      "Epoch 219/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0783 - val_accuracy: 0.9745\n",
      "Epoch 220/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9815 - val_loss: 0.0896 - val_accuracy: 0.9680\n",
      "Epoch 221/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9808 - val_loss: 0.0738 - val_accuracy: 0.9755\n",
      "Epoch 222/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9847 - val_loss: 0.0776 - val_accuracy: 0.9780\n",
      "Epoch 223/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.0744 - val_accuracy: 0.9760\n",
      "Epoch 224/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9843 - val_loss: 0.0742 - val_accuracy: 0.9750\n",
      "Epoch 225/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9812 - val_loss: 0.0769 - val_accuracy: 0.9735\n",
      "Epoch 226/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9824 - val_loss: 0.0786 - val_accuracy: 0.9725\n",
      "Epoch 227/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.0999 - val_accuracy: 0.9655\n",
      "Epoch 228/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0789 - val_accuracy: 0.9725\n",
      "Epoch 229/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9809 - val_loss: 0.0810 - val_accuracy: 0.9735\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 0.0841 - val_accuracy: 0.9680\n",
      "Epoch 231/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9739 - val_loss: 0.1077 - val_accuracy: 0.9630\n",
      "Epoch 232/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9754 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 233/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.0935 - val_accuracy: 0.9755\n",
      "Epoch 234/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.0759 - val_accuracy: 0.9800\n",
      "Epoch 235/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.0787 - val_accuracy: 0.9710\n",
      "Epoch 236/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.0708 - val_accuracy: 0.9795\n",
      "Epoch 237/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9833 - val_loss: 0.0729 - val_accuracy: 0.9790\n",
      "Epoch 238/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9818 - val_loss: 0.0771 - val_accuracy: 0.9740\n",
      "Epoch 239/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9833 - val_loss: 0.0755 - val_accuracy: 0.9745\n",
      "Epoch 240/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.0767 - val_accuracy: 0.9775\n",
      "Epoch 241/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9793 - val_loss: 0.0914 - val_accuracy: 0.9690\n",
      "Epoch 242/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9818 - val_loss: 0.0746 - val_accuracy: 0.9770\n",
      "Epoch 243/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9805 - val_loss: 0.0857 - val_accuracy: 0.9695\n",
      "Epoch 244/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9797 - val_loss: 0.0855 - val_accuracy: 0.9715\n",
      "Epoch 245/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 0.0827 - val_accuracy: 0.9730\n",
      "Epoch 246/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.0751 - val_accuracy: 0.9795\n",
      "Epoch 247/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.0733 - val_accuracy: 0.9745\n",
      "Epoch 248/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9851 - val_loss: 0.0768 - val_accuracy: 0.9765\n",
      "Epoch 249/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9837 - val_loss: 0.0719 - val_accuracy: 0.9785\n",
      "Epoch 250/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 0.0874 - val_accuracy: 0.9650\n",
      "Epoch 251/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9781 - val_loss: 0.0756 - val_accuracy: 0.9735\n",
      "Epoch 252/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.0818 - val_accuracy: 0.9735\n",
      "Epoch 253/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9800 - val_loss: 0.0793 - val_accuracy: 0.9770\n",
      "Epoch 254/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 0.0702 - val_accuracy: 0.9785\n",
      "Epoch 255/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.0732 - val_accuracy: 0.9765\n",
      "Epoch 256/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9791 - val_loss: 0.0722 - val_accuracy: 0.9780\n",
      "Epoch 257/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.1050 - val_accuracy: 0.9635\n",
      "Epoch 258/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 0.0956 - val_accuracy: 0.9690\n",
      "Epoch 259/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 0.0761 - val_accuracy: 0.9770\n",
      "Epoch 260/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9796 - val_loss: 0.0761 - val_accuracy: 0.9700\n",
      "Epoch 261/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0813 - val_accuracy: 0.9695\n",
      "Epoch 262/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.0861 - val_accuracy: 0.9660\n",
      "Epoch 263/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 0.0730 - val_accuracy: 0.9770\n",
      "Epoch 264/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.0821 - val_accuracy: 0.9765\n",
      "Epoch 265/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 0.0898 - val_accuracy: 0.9720\n",
      "Epoch 266/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.1098 - val_accuracy: 0.9625\n",
      "Epoch 267/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9805 - val_loss: 0.0811 - val_accuracy: 0.9725\n",
      "Epoch 268/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.0802 - val_accuracy: 0.9740\n",
      "Epoch 269/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.0990 - val_accuracy: 0.9700\n",
      "Epoch 270/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.0941 - val_accuracy: 0.9695\n",
      "Epoch 271/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9803 - val_loss: 0.0873 - val_accuracy: 0.9700\n",
      "Epoch 272/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.0792 - val_accuracy: 0.9700\n",
      "Epoch 273/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9794 - val_loss: 0.0785 - val_accuracy: 0.9745\n",
      "Epoch 274/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.0844 - val_accuracy: 0.9700\n",
      "Epoch 275/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 0.0772 - val_accuracy: 0.9740\n",
      "Epoch 276/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9835 - val_loss: 0.0865 - val_accuracy: 0.9705\n",
      "Epoch 277/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.0784 - val_accuracy: 0.9745\n",
      "Epoch 278/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9824 - val_loss: 0.0710 - val_accuracy: 0.9775\n",
      "Epoch 279/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9856 - val_loss: 0.0705 - val_accuracy: 0.9790\n",
      "Epoch 280/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9822 - val_loss: 0.0735 - val_accuracy: 0.9780\n",
      "Epoch 281/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9827 - val_loss: 0.0740 - val_accuracy: 0.9760\n",
      "Epoch 282/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.0730 - val_accuracy: 0.9770\n",
      "Epoch 283/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.0717 - val_accuracy: 0.9780\n",
      "Epoch 284/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9781 - val_loss: 0.0725 - val_accuracy: 0.9780\n",
      "Epoch 285/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.0716 - val_accuracy: 0.9765\n",
      "Epoch 286/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9845 - val_loss: 0.0705 - val_accuracy: 0.9775\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0739 - val_accuracy: 0.9760\n",
      "Epoch 288/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.0735 - val_accuracy: 0.9770\n",
      "Epoch 289/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9849 - val_loss: 0.0775 - val_accuracy: 0.9770\n",
      "Epoch 290/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9809 - val_loss: 0.0777 - val_accuracy: 0.9770\n",
      "Epoch 291/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9770 - val_loss: 0.0844 - val_accuracy: 0.9770\n",
      "Epoch 292/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 0.0717 - val_accuracy: 0.9775\n",
      "Epoch 293/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9839 - val_loss: 0.0710 - val_accuracy: 0.9800\n",
      "Epoch 294/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9826 - val_loss: 0.0703 - val_accuracy: 0.9800\n",
      "Epoch 295/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9826 - val_loss: 0.0847 - val_accuracy: 0.9745\n",
      "Epoch 296/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 0.0741 - val_accuracy: 0.9780\n",
      "Epoch 297/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 0.0760 - val_accuracy: 0.9730\n",
      "Epoch 298/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.0930 - val_accuracy: 0.9735\n",
      "Epoch 299/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0788 - val_accuracy: 0.9730\n",
      "Epoch 300/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9822 - val_loss: 0.0775 - val_accuracy: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21632... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>â–ƒâ–‚â–ƒâ–‚â–â–…â–…â–ƒâ–…â–‚â–„â–†â–…â–„â–„â–†â–‡â–‡â–„â–…â–‡â–…â–‡â–†â–†â–„â–†â–‡â–†â–ˆâ–†â–†â–„â–†â–„â–†â–‡â–ƒâ–ˆâ–†</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–ˆâ–‡â–‡â–‡â–…â–…â–…â–„â–…â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–„â–â–‚</td></tr><tr><td>val_accuracy</td><td>â–„â–ƒâ–„â–„â–‚â–…â–‡â–‡â–„â–„â–†â–†â–…â–†â–…â–‡â–ƒâ–„â–„â–„â–†â–‚â–ˆâ–‡â–†â–„â–â–‡â–‚â–†â–„â–ˆâ–„â–…â–ƒâ–…â–ƒâ–‡â–‡â–†</td></tr><tr><td>val_loss</td><td>â–ˆâ–ˆâ–‡â–†â–‡â–…â–„â–„â–…â–„â–„â–„â–„â–‚â–ƒâ–ƒâ–„â–‚â–†â–‚â–ƒâ–„â–â–â–‚â–ƒâ–†â–ƒâ–…â–‚â–‚â–â–„â–ƒâ–‚â–ƒâ–„â–â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98225</td></tr><tr><td>best_epoch</td><td>253</td></tr><tr><td>best_val_loss</td><td>0.07019</td></tr><tr><td>epoch</td><td>299</td></tr><tr><td>loss</td><td>0.0553</td></tr><tr><td>val_accuracy</td><td>0.9755</td></tr><tr><td>val_loss</td><td>0.07749</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">colorful-firefly-15</strong>: <a href=\"https://wandb.ai/yhkim/Innopia4/runs/2rw09tz9\" target=\"_blank\">https://wandb.ai/yhkim/Innopia4/runs/2rw09tz9</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20221014_002123-2rw09tz9\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Innopia4\", entity=\"yhkim\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 300,\n",
    "  \"batch_size\" : 128\n",
    "}\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=wandb.config['learning_rate']), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=wandb.config['batch_size'], validation_batch_size=wandb.config['batch_size'], epochs=wandb.config['epochs'], callbacks=[WandbCallback()])\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(columns=['x','y','label'])\n",
    "for _ in range(10000):\n",
    "    x = np.random.randint(0, 800)\n",
    "    y = np.random.randint(0, 800)\n",
    "    label = labels[y][x]\n",
    "    temp = pd.DataFrame({'x':[x], 'y':[y], 'label':[label]})\n",
    "\n",
    "    test_data = test_data.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=['label']).values\n",
    "y_test = test_data['label'].values\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.int32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07072202116250992, 0.9783999919891357]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adam lr : 0.01\n",
    " 1. [0.15516355633735657, 0.9478999972343445]\n",
    " \n",
    "- Adam lr : 0.01\n",
    " 2. [0.07072202116250992, 0.9783999919891357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a399d4c4514d125852f3bc51ca0a6706781da022d47c4cd91c80cf905a19a6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
